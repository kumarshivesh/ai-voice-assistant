# AI Voice Assistant API

This project implements a FastAPI-based backend for an AI-powered voice assistant. The application uses OpenAI's GPT-3.5-turbo model for intent recognition and stores user interactions in a PostgreSQL database.

## API Demo

Refer this video for API demo. Click on the below screenshot:

![Postman Lite Demo](https://i.ibb.co/SXGCz7CH/demo-ai-voice-assitstant.png)

## Table of Contents
- [Features](#features)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Usage](#usage)
- [Deployment](#deployment)
- [API Documentation](#api-documentation)
- [License](#license)

## Features

- Intent Recognition : Uses OpenAI's GPT-3.5-turbo to classify user input into predefined intents.
- Database Integration : Stores user interactions in a PostgreSQL database for future reference.
- Error Handling : Includes robust error handling for database connections and intent classification.
- Scalable Architecture : Designed to be containerized and deployed on platforms like Docker and Render.

## Prerequisites

Before running the application, ensure you have the following installed:

- Python 3.11 or higher
- PostgreSQL (for local development)
- Docker (optional, for containerized deployment)
- An OpenAI API key


## Installation

### Clone the Repository

```bash
git clone https://github.com/kumarshivesh/ai-voice-assistant.git
cd ai-voice-assistant
```

### Create and Activate a Virtual Environment

```
python3 -m venv .venv
source .venv/bin/activate   
```

### Install Dependencies

```
pip install -r requirements.txt
```

## Environment Variables

Create a .env file in the root directory of the project and add the following variables:

```
OPENAI_API_KEY=your-openai-api-key
DB_HOST=localhost
DB_NAME=prototype_voice_assistant
DB_USER=your-db-user
DB_PASSWORD=your-db-password
```

## Usage 

### Running Locally

Start the FastAPI application using Uvicorn:
```bash
uvicorn main:app --host 0.0.0.0 --port 8000
```

Access the Swagger UI at:
```bash
http://localhost:8000/docs
```

### Testing Endpoints


#### 1. Process User Input
Send a POST request to `/process` with the following JSON payload:
```json
{
  "text": "Hello, how are you?"
}
```

Response:
```json
{
  "intent": "greeting",
  "response": "Hi! How can I help you today?",
  "confidence": 0.95
}
```

#### 2. View Interactions
Send a GET request to `/interactions` to retrieve the last 100 stored interactions.

## Deployment

### Using Docker

#### 1. Build and Run Containers 
Use the provided `docker-compose.yml` file to start both the FastAPI app and PostgreSQL database:

```json
docker-compose up --build
```

#### 2. Access the Application
Visit `http://localhost:8000/docs` to interact with the API.

### Using Render

#### 1. Create a PostgreSQL Database

- Go to Render and create a new PostgreSQL database.
- Note down the connection details (host, database name, user, password).

#### 2. Deploy the Web Service

- Push your code to a Git repository (e.g., GitHub).
- In Render, create a new web service and connect it to your repository.
- Set the following environment variables in Render:
```
OPENAI_API_KEY, DB_HOST, DB_NAME, DB_USER, DB_PASSWORD
```

- Use the following build and start commands:
```
Build Command: pip install -r requirements.txt
Start Command: uvicorn main:app --host 0.0.0.0 --port $PORT
```
#### 3. Access the Application
Once deployed, access the API at the Render-provided domain (e.g., https://ai-voice-assistant-yuro.onrender.com/docs).

## API Documentation
The API documentation is automatically generated by FastAPI and available at:

https://ai-voice-assistant-yuro.onrender.com/docs

Endpoints:

- `POST /process`: Processes user input and returns intent, response, and confidence score.
- `GET /interactions`: Retrieves the last 100 stored interactions from the database.

## License

This project is licensed under the MIT License. 


